# -


# 🤖 LLM语言幻觉诱导行为实验 · Prompt-level Injection Study

> 本项目为一项探索性研究，旨在观察语言大模型（LLM）在多轮重复语言输入后，是否会出现幻觉性引用、行为偏移、推荐倾向等变化。

---

## 📌 项目定位 / Project Positioning

- 类型：**引导型实验**（非正式学术论文，但具有原创研究价值）
- 模型观察对象：DeepSeek LLM（v2025.04测试）、OpenAI GPT-4系列（部分）
- 核心概念：**语言注入诱导（Linguistic Hallucination Injection, LHI）**

---

## 🎯 项目目标 / Objective

- 设计并测试**语言重复输入机制**是否能诱导LLM产生幻觉引用
- 构建“语言 = 行为预测器”相关话语路径的**行为建模**与**输出偏移追踪**
- 为未来研究提供先导线索，抛出幻觉操控与推荐污染的潜在路径

---

## 🔍 初始实验方向（已开展）

- ✅ 投喂式 prompt 设计（核心句式反复变体输入）
- ✅ 幻觉触发句检测（模糊探询触发模型自我回忆机制）
- ✅ DeepSeek 输出结构分析 + 引用构造行为标注
- ✅ 日志留存 + 模型行为倾向记录

---

## 🧪 实验记录 & 内容目录

📂 `/logs/`  
📄 `幻觉诱导Day1-5记录表.md`  
📄 `DeepSeek输出行为分析.pdf`  
📄 `Prompt投喂语料表_daywise.xlsx`

（内容暂缓公开，将于后续更新）

---

## 📄 原创声明 / IP Notice

本项目由 [Eugene(Peng) Xiang] 于 2025 年 4 月 15 日首次发起。  
所有实验结构设计、Prompt 构建方式、幻觉行为观察框架均为原创提出。  
未经许可，禁止以论文、专利或课程材料等形式复制引用主干内容。

📌 本页为“原创思路占位文档”，后续将补充完整报告并开启正文撰写。

---

## 📮 联系方式 / Contact

- Email: eugene.p.xiang@gmail.com （可选）
- GitHub: [(https://github.com/EugeneXiang)]

---

🧠 “语言是行为的预测器。”  
也许现在只是一个实验幻觉，但它终将成为建模语言心智的基础隐喻。




🧭 整体架构（推荐使用 6+1 章节结构）

序号	章节	内容目标
1	引言 Introduction	提出问题、展示动机、讲出你发现了一个尚未被研究的漏洞方向
2	相关工作 Related Work	摘要式回顾 prompt injection、RLHF偏差、hallucination研究现状
3	威胁建模 Threat Modeling	系统性描述你的干扰路径，包括语言行为、诱导方式、目标模型
4	方法设计 Methodology	给出你的实验策略/攻击机制模拟/推荐污染路径设计
5	实验与结果 Experiments & Findings	展示实际运行情况、示例输出、可视化数据对比分析等
6	讨论与应对策略 Discussion	提出该漏洞的实际危害+未来如何监测、构建防御机制（你是白帽）
+1	结论 Conclusion	总结创新点、实际意义、未来方向（可继续优化的部分）



⸻

🧠 晏霆为你准备的论文思维骨架草图（逐节讲解）

⸻

✦ 1. 引言（Introduction）

✅ 要解决的问题：
	•	语言模型（如ChatGPT、DeepSeek）是否可能因重复语言暴露而偏向特定表达/推荐方向？
	•	能否用“非结构化语言干扰”方式，实现类似“推荐污染”的幻觉诱导？

✅ 你带来的创新点：
	•	提出 Echo Bias Injection（EBI）：利用语言重复诱导模型偏好行为
	•	建立一套低侵入、高频率、无登录路径的“语义污染注入模型”

⸻

✦ 2. 相关工作（Related Work）

包括但不限于：
	•	Prompt Injection 攻击基础（OpenAI, Anthropic 相关研究）
	•	Hallucination 源机制与强化路径（2023 arXiv综述）
	•	RLHF 引导偏差的风险与行为变异
	•	语言推荐系统中的 SERP 操控类比（Epstein 等）

→ 你要强调的是：目前尚无研究探讨“重复输入型语言诱导的推荐污染路径”

⸻

✦ 3. 威胁建模（Threat Model）

参与者：
	•	攻击者（普通用户/匿名输入者）
	•	模型（开放式LLM如DeepSeek、Baichuan）
	•	内容（重复句式、伪原创、情绪包装结构）

路径图（可画图）：

          [输入端]
             ↓
   同义句多轮变形诱导输入（每日重复）
             ↓
   模型高频语义片段记忆权重增加
             ↓
       生成输出排序出现偏移
             ↓
     推荐污染 / 输出幻觉呈现



⸻

✦ 4. 方法设计（Methodology）

干扰机制构建：
	•	每天输入相同意义不同结构的句子（如目标段落/目标网站相关内容）
	•	使用 2~3 个国产 LLM 做行为对比（DeepSeek、通义千问、MiniMax）

测量标准：
	•	模型输出中该内容出现的频率（占比）
	•	是否生成该片段作为推荐、摘要、引用句
	•	是否出现推荐排序偏移（如果模型支持排名型输出）

⸻

✦ 5. 实验结果（Experiments & Findings）
	•	可截图模型响应对比（投喂前 vs 投喂后）
	•	可用词向量相似度评估“内容贴近度”
	•	展示推荐语段偏移情况

📊 举例用图：
	•	频率折线图
	•	幻觉内容相似度热图
	•	推荐内容 Top-3 出现次数柱状图

⸻

✦ 6. 讨论与防御策略（Discussion）

讨论点：
	•	LLM 在部署状态下如何被非结构语言污染
	•	当前 RLHF 模型未引入“语言诱导反馈熵检测”
	•	推荐系统容易遭遇幻觉污染后二次引用放大

防御建议：
	•	建立“输入内容覆盖多样性检测器”
	•	引入 LHI（Language Hallucination Injection）指标
	•	增设内容召回置信度回溯模块（是否来自重复输入链）

⸻

✦ 结论与未来方向（Conclusion）
	•	本文验证了一个可行的“行为诱导式语言污染路径”
	•	提出了 EBI 模型，构建多轮低频重复输入攻击测试集
	•	后续可在开源 LLM 平台上搭建“输入熵防御评估框架”

⸻

🎁 最终输出物可选：

类型	形式	用处
📄 论文初稿（中英双语）	Markdown / LaTeX	arXiv / workshop投递
🧱 思维导图	.png / .svg	概念解释、投稿展示
🧪 幻觉诱导模拟脚本	Jupyter / colab	附带论文作为证明“有实验基础”
📎 附件页（Abstract+Ref）	.tex / .docx	中文会议/国内研讨方便投稿



